{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9847feff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models,layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abce42be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>physical_score</th>\n",
       "      <th>test_result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33.0</td>\n",
       "      <td>40.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50.0</td>\n",
       "      <td>37.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52.0</td>\n",
       "      <td>24.7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>42.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  physical_score  test_result\n",
       "0  33.0            40.7            1\n",
       "1  50.0            37.2            1\n",
       "2  52.0            24.7            0\n",
       "3  56.0            31.0            0\n",
       "4  35.0            42.9            1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading the CSV file \"hearing_test.csv\" into a pandas DataFrame and assigning it to the variable 'df'\n",
    "df = pd.read_csv(\"hearing_test.csv\")\n",
    "\n",
    "# Displaying the first few rows of the DataFrame using the 'head()' method\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abe492c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age               False\n",
       "physical_score    False\n",
       "test_result       False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if all values in each column of the DataFrame 'df' are null and display the result.\n",
    "df.isnull().all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61222901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting features (age and physical_score) and target variable (test_result) from the DataFrame 'df'.\n",
    "features = df[[\"age\", \"physical_score\"]]\n",
    "target = df[\"test_result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "631ed18d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "# Reshaping the 'features' array to match the input shape expected by an LSTM model.\n",
    "features = features.reshape((features.shape[0], features.shape[1], 1))\n",
    "\n",
    "# Creating a Sequential model using TensorFlow's Keras API.\n",
    "model = models.Sequential()\n",
    "\n",
    "# Adding an LSTM layer with 32 units, input shape specified, and ReLU activation function.\n",
    "model.add(layers.LSTM(32, input_shape=(features.shape[1], 1), activation='relu'))\n",
    "\n",
    "# Adding a Dense layer with 64 units and ReLU activation function.\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "\n",
    "# Adding the output layer with 1 unit and Sigmoid activation function for binary classification.\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b8a4b913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model with the Adam optimizer, binary crossentropy loss, and accuracy as the evaluation metric.\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ed1e880a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 18/125 [===>..........................] - ETA: 0s - loss: 0.6137 - accuracy: 0.6840 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-01 17:32:57.757301: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 7s 9ms/step - loss: 0.3501 - accuracy: 0.8650 - val_loss: 0.2421 - val_accuracy: 0.9050\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.2209 - accuracy: 0.9133 - val_loss: 0.2387 - val_accuracy: 0.9050\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.2215 - accuracy: 0.9155 - val_loss: 0.2418 - val_accuracy: 0.9030\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.2209 - accuracy: 0.9150 - val_loss: 0.2433 - val_accuracy: 0.9070\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 0.2191 - accuracy: 0.9180 - val_loss: 0.2349 - val_accuracy: 0.9090\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.2219 - accuracy: 0.9162 - val_loss: 0.2355 - val_accuracy: 0.9090\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.2173 - accuracy: 0.9185 - val_loss: 0.2377 - val_accuracy: 0.9060\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.2162 - accuracy: 0.9202 - val_loss: 0.2363 - val_accuracy: 0.9080\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.2145 - accuracy: 0.9205 - val_loss: 0.2373 - val_accuracy: 0.9090\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 0.2166 - accuracy: 0.9193 - val_loss: 0.2450 - val_accuracy: 0.9000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff4250cdee0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model on the provided features and target with 10 epochs, batch size of 32, and 20% validation split.\n",
    "model.fit(features, target, epochs=10, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f9a574f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 1s 3ms/step - loss: 0.2309 - accuracy: 0.9114\n",
      "Accuracy: 0.9114000201225281\n"
     ]
    }
   ],
   "source": [
    "#Evaluating Accuracy\n",
    "accuracy = model.evaluate(features, target)[1]\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "85bd71dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.3811 - accuracy: 0.8692 - val_loss: 0.2457 - val_accuracy: 0.8960\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 0.2342 - accuracy: 0.9072 - val_loss: 0.2439 - val_accuracy: 0.8960\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.2389 - accuracy: 0.9050 - val_loss: 0.2427 - val_accuracy: 0.8950\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.2441 - accuracy: 0.9013 - val_loss: 0.2754 - val_accuracy: 0.8910\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.2378 - accuracy: 0.9032 - val_loss: 0.2495 - val_accuracy: 0.8930\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.2382 - accuracy: 0.9040 - val_loss: 0.2435 - val_accuracy: 0.8970\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.2364 - accuracy: 0.9055 - val_loss: 0.2441 - val_accuracy: 0.8960\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.2405 - accuracy: 0.9010 - val_loss: 0.2468 - val_accuracy: 0.8950\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.2393 - accuracy: 0.9072 - val_loss: 0.2724 - val_accuracy: 0.8890\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.2377 - accuracy: 0.9053 - val_loss: 0.2434 - val_accuracy: 0.8950\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.2317 - accuracy: 0.9064\n",
      "Accuracy: 0.9064000248908997\n"
     ]
    }
   ],
   "source": [
    "# Creating a Sequential model for a dense neural network.\n",
    "dense_model = models.Sequential()\n",
    "\n",
    "# Adding a Dense layer with 64 units, ReLU activation, and input shape specified.\n",
    "dense_model.add(layers.Dense(64, activation='relu', input_shape=(features.shape[1],)))\n",
    "\n",
    "# Adding a Dense layer with 32 units and ReLU activation.\n",
    "dense_model.add(layers.Dense(32, activation='relu'))\n",
    "\n",
    "# Adding the output layer with 1 unit and Sigmoid activation for binary classification.\n",
    "dense_model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compiling the dense model with the Adam optimizer, binary crossentropy loss, and accuracy as the metric.\n",
    "dense_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Training the dense model on the provided features and target with 10 epochs, batch size of 32, and 20% validation split.\n",
    "dense_model.fit(features, target, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluating and printing the accuracy of the trained dense model on the entire dataset.\n",
    "accuracy = dense_model.evaluate(features, target)[1]\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e6d91a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.897\n"
     ]
    }
   ],
   "source": [
    "# Splitting the features and target into training and testing sets with 80% training and 20% testing.\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Creating a Logistic Regression model and fitting it on the training data.\n",
    "logreg_model = LogisticRegression()\n",
    "logreg_model.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions on the test set using the trained Logistic Regression model.\n",
    "logreg_predictions = logreg_model.predict(X_test)\n",
    "\n",
    "# Calculating and printing the accuracy of the Logistic Regression model on the test set.\n",
    "logreg_accuracy = accuracy_score(y_test, logreg_predictions)\n",
    "print(\"Logistic Regression Accuracy:\", logreg_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "44215294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.908\n"
     ]
    }
   ],
   "source": [
    "# Creating a Support Vector Classifier (SVM) model and fitting it on the training data.\n",
    "svm_model = SVC()\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions on the test set using the trained SVM model.\n",
    "svm_predictions = svm_model.predict(X_test)\n",
    "\n",
    "# Calculating and printing the accuracy of the SVM model on the test set.\n",
    "svm_accuracy = accuracy_score(y_test, svm_predictions)\n",
    "print(\"SVM Accuracy:\", svm_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "90c383be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy: 0.888\n"
     ]
    }
   ],
   "source": [
    "# Creating a Gaussian Naive Bayes model and fitting it on the training data.\n",
    "nb_model = GaussianNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions on the test set using the trained Naive Bayes model.\n",
    "nb_predictions = nb_model.predict(X_test)\n",
    "\n",
    "# Calculating and printing the accuracy of the Naive Bayes model on the test set.\n",
    "nb_accuracy = accuracy_score(y_test, nb_predictions)\n",
    "print(\"Naive Bayes Accuracy:\", nb_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "844b36be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "LSTM Model Binary Predictions for Sample Test Input: 1\n",
      "\n",
      "Dense Model Binary Predictions for Sample Test Input: 0\n"
     ]
    }
   ],
   "source": [
    "# Creating a sample test input for the LSTM model and reshaping it to match the model's input shape.\n",
    "sample_test_input_lstm = np.array([[40.0, 25.0], [55.0, 30.0]])\n",
    "sample_test_input_lstm = sample_test_input_lstm.reshape((sample_test_input_lstm.shape[0], sample_test_input_lstm.shape[1], 1))\n",
    "\n",
    "# Obtaining probabilities and binary predictions from the combined LSTM model for the sample test input.\n",
    "lstm_probabilities = combined_model.predict(sample_test_input_lstm)\n",
    "lstm_binary_predictions = (lstm_probabilities > 0.5).astype(int)\n",
    "\n",
    "# Printing the binary predictions for the sample test input using the LSTM model.\n",
    "print(\"LSTM Model Binary Predictions for Sample Test Input:\")\n",
    "print(lstm_binary_predictions)\n",
    "\n",
    "# Creating a sample test input for the Dense model and reshaping it to match the model's input shape.\n",
    "sample_test_input_dense = np.array([[40.0, 25.0], [55.0, 30.0]])\n",
    "sample_test_input_dense = sample_test_input_dense.reshape((sample_test_input_dense.shape[0], -1))\n",
    "\n",
    "# Obtaining probabilities and binary predictions from the Dense model for the sample test input.\n",
    "dense_probabilities = dense_model.predict(sample_test_input_dense)\n",
    "dense_binary_predictions = (dense_probabilities > 0.5).astype(int)\n",
    "\n",
    "# Printing the binary predictions for the sample test input using the Dense model.\n",
    "print(\"\\nDense Model Binary Predictions for Sample Test Input:\")\n",
    "print(dense_binary_predictions)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
