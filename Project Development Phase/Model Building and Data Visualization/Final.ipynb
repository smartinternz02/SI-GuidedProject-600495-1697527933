{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1ea9e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-07 14:56:40.514084: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-07 14:56:40.877966: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-07 14:56:41.784470: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/aaron/anaconda3/envs/tf/lib/\n",
      "2023-11-07 14:56:41.784599: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/aaron/anaconda3/envs/tf/lib/\n",
      "2023-11-07 14:56:41.784608: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models,layers,optimizers,callbacks\n",
    "from tensorflow.keras.models import load_model, save_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53401700",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>physical_score</th>\n",
       "      <th>test_result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33.0</td>\n",
       "      <td>40.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50.0</td>\n",
       "      <td>37.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52.0</td>\n",
       "      <td>24.7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>42.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  physical_score  test_result\n",
       "0  33.0            40.7            1\n",
       "1  50.0            37.2            1\n",
       "2  52.0            24.7            0\n",
       "3  56.0            31.0            0\n",
       "4  35.0            42.9            1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read data from a CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(\"hearing_test.csv\")\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f0c64e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age               False\n",
       "physical_score    False\n",
       "test_result       False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if there are any columns with all null values in the DataFrame\n",
    "df.isnull().all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1410632e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting features and target from the DataFrame\n",
    "features = df[[\"age\", \"physical_score\"]]\n",
    "target = df[\"test_result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9504d74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize MinMaxScaler for scaling features to a specified range\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Scaling the selected features using the MinMaxScaler\n",
    "features_scaled = scaler.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "410398e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the scaled features and target into training and validation sets\n",
    "features_train, features_val, target_train, target_val = train_test_split(features_scaled, target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43089623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-07 14:58:57.458522: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-07 14:58:57.494277: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-07 14:58:57.494565: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-07 14:58:57.495283: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-07 14:58:57.497258: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-07 14:58:57.497508: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-07 14:58:57.497704: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-07 14:58:58.332272: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-07 14:58:58.333380: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-07 14:58:58.333784: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-07 14:58:58.334059: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2114 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      " 17/125 [===>..........................] - ETA: 0s - loss: 0.6847 - accuracy: 0.6507"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-07 14:59:01.608834: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 5s 15ms/step - loss: 0.6792 - accuracy: 0.5960 - val_loss: 0.6662 - val_accuracy: 0.6160\n",
      "Epoch 2/50\n",
      "125/125 [==============================] - 1s 12ms/step - loss: 0.6724 - accuracy: 0.5960 - val_loss: 0.6487 - val_accuracy: 0.6160\n",
      "Epoch 3/50\n",
      "125/125 [==============================] - 2s 12ms/step - loss: 0.4988 - accuracy: 0.7500 - val_loss: 0.3635 - val_accuracy: 0.8550\n",
      "Epoch 4/50\n",
      "125/125 [==============================] - 2s 13ms/step - loss: 0.3309 - accuracy: 0.8717 - val_loss: 0.3413 - val_accuracy: 0.8690\n",
      "Epoch 5/50\n",
      "125/125 [==============================] - 1s 11ms/step - loss: 0.2861 - accuracy: 0.8910 - val_loss: 0.3214 - val_accuracy: 0.8840\n",
      "Epoch 6/50\n",
      "125/125 [==============================] - 2s 13ms/step - loss: 0.2698 - accuracy: 0.8963 - val_loss: 0.2826 - val_accuracy: 0.8850\n",
      "Epoch 7/50\n",
      "125/125 [==============================] - 1s 12ms/step - loss: 0.2658 - accuracy: 0.8980 - val_loss: 0.2826 - val_accuracy: 0.8820\n",
      "Epoch 8/50\n",
      "125/125 [==============================] - 1s 11ms/step - loss: 0.2671 - accuracy: 0.9020 - val_loss: 0.2987 - val_accuracy: 0.8830\n",
      "Epoch 9/50\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 0.2526 - accuracy: 0.9115 - val_loss: 0.2990 - val_accuracy: 0.8790\n",
      "Epoch 10/50\n",
      "125/125 [==============================] - 2s 13ms/step - loss: 0.2480 - accuracy: 0.9065 - val_loss: 0.2836 - val_accuracy: 0.8960\n",
      "Epoch 11/50\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 0.2377 - accuracy: 0.9097 - val_loss: 0.2673 - val_accuracy: 0.8870\n",
      "Epoch 12/50\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 0.2306 - accuracy: 0.9178 - val_loss: 0.2533 - val_accuracy: 0.9000\n",
      "Epoch 13/50\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 0.2158 - accuracy: 0.9183 - val_loss: 0.2435 - val_accuracy: 0.9020\n",
      "Epoch 14/50\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 0.2090 - accuracy: 0.9190 - val_loss: 0.2437 - val_accuracy: 0.9070\n",
      "Epoch 15/50\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.2085 - accuracy: 0.9180 - val_loss: 0.2342 - val_accuracy: 0.9030\n",
      "Epoch 16/50\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 0.2049 - accuracy: 0.9185 - val_loss: 0.2373 - val_accuracy: 0.9040\n",
      "Epoch 17/50\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 0.1947 - accuracy: 0.9260 - val_loss: 0.2364 - val_accuracy: 0.9040\n",
      "Epoch 18/50\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 0.1982 - accuracy: 0.9215 - val_loss: 0.2490 - val_accuracy: 0.9030\n",
      "Epoch 19/50\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 0.1991 - accuracy: 0.9250 - val_loss: 0.2433 - val_accuracy: 0.9050\n",
      "Epoch 20/50\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 0.1951 - accuracy: 0.9245 - val_loss: 0.2741 - val_accuracy: 0.8890\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2342 - accuracy: 0.9030\n",
      "Validation Accuracy: 0.902999997138977\n"
     ]
    }
   ],
   "source": [
    "# Create a sequential model\n",
    "model = models.Sequential()\n",
    "\n",
    "# Add LSTM layers to the model with specified parameters\n",
    "model.add(layers.LSTM(64, input_shape=(features.shape[1], 1), activation='relu', return_sequences=True))\n",
    "model.add(layers.Dropout(0.1))\n",
    "model.add(layers.LSTM(32, activation='relu', return_sequences=True))\n",
    "model.add(layers.Dropout(0.1))\n",
    "model.add(layers.LSTM(16, activation='relu'))\n",
    "model.add(layers.Dropout(0.1))\n",
    "\n",
    "# Add dense layers to the model\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model with specified optimizer, loss function, and metrics\n",
    "model.compile(optimizer=optimizers.Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define early stopping to prevent overfitting\n",
    "early_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Train the model on the training data, with validation data and early stopping\n",
    "history = model.fit(features_train, target_train, epochs=50, batch_size=32, validation_data=(features_val, target_val), callbacks=[early_stopping])\n",
    "\n",
    "# Evaluate the model on the validation set and print the accuracy\n",
    "accuracy = model.evaluate(features_val, target_val)[1]\n",
    "print(\"Validation Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08b94ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model to an HDF5 file\n",
    "model.save(\"model.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
